# Data-Analytics-Essentials-by-Cisco

1) Analytics in real time -
Topic Objective: Explain the value of data analytics. <br>
The availability of real-time data now makes possible the analysis of many types of data from numerous sources. This data can be analyzed to provide actionable insights on which all types of organizations can base decisions.
2) Data Analytics in Action -
Topic Objective: Describe the phases in the analytic process. <br>
The six phases of the analytic process are Asking the question, Getting the data, Investigating the data, Preparing the data, Analyzing the data, and Presenting the results. In real-world applications, the process is iterative.


There are four key types of data analytics: Descriptive, Predictive, Prescriptive, and Diagnostic. Used in combination, they can provide a thorough understanding of a business's needs and opportunities.
## Different Types of Analysis
Selectable image component. Select each item to show more information.
In a technical sense, data analytics can be described as the process of using data to answer questions, identify trends, and extract insights. There are multiple types of analytics that can generate information to drive innovation, improve efficiency, and mitigate risk.

There are four key types of data analytics, and each answers a different type of question:

-Descriptive analytics asks, “What happened?” <br>
-Predictive analytics asks, “What might happen in the future?”<br>
-Prescriptive analytics asks, “What should be done next?”<br>
-Diagnostic analytics asks, “Why did this happen?”<br>

Each of the above types has its own unique insights, advantages, and disadvantages. Used in combination they provide a more complete understanding of the business's needs and opportunities.

## Descriptive Analytics
Descriptive analytics primarily uses observed data to identify key characteristics of a data set. It relies solely on historical data to provide reports on past events. This type of analysis is also used to generate ad hoc (as needed) reports that summarize large amounts of data to answer simple questions like “how much?” or “how many?” It can also be used to ask deeper questions about a specific problem. Descriptive analytics is not used to draw inferences or predictions from its findings; it is just a starting point used to inform decisions or to prepare data for further analysis.

The descriptive analytics process is as follows:

-Ask a historical question that needs an answer, such as “How much of product X did we sell last year?”<br>
-Identify required data to answer the question<br>
-Collect and prepare data<br>
-Analyze data<br>
-Present results<br>

Examples of descriptive analytics include:

-Summarizing historical events such as sales, inventory, or operations data <br>
-Understanding engagement data such as likes and dislikes or volume of page views over time<br>
-Reporting general trends like revenue growth or employee injuries<br>
-Collating survey results

## Predictive Analytics
Predictive analytics utilizes real-time and/or past data to make predictions based on probabilities. It can also be used to infer missing data or establish a predicted future trend. Predictive analytics uses simulation models and forecasting to suggest what could happen going forward, which can guide realistic goal setting, effective planning, management of performance expectations, and avoiding risks. This information can empower executives and managers to take a proactive and fact-based approach to strategy and decision making.

The predictive analytics process is as follows:

-Ask a forward-thinking question, such as “Can we predict how much product X we will sell next year?” <br>
-Collect and prepare data <br>
-Develop predictive analytics models <br>
-Apply models to the prepared data <br>
-Review models and present results <br>
Examples of predictive analytics include: 

-Forecasting customer behavior, purchasing patterns, and identifying sales trends <br>
-Predicting customer preferences and recommending products to customers based on past purchases and search history<br>
-Predicting the likelihood that a given customer will purchase another product or leave the store<br>
-Identifying possible security breaches that require further investigation<br>
-Predicting staffing and resourcing needs


## Prescriptive Analytics
Prescriptive analytics builds on descriptive and predictive analysis by recommending courses of action that will reap the greatest benefit for the organization. In short, prescriptive analytics tells you what should be done in a given situation. It helps executives, managers, and employees make the best decisions based on available data.

A good example of prescriptive analytics is the field of GPS-based map and direction applications. These applications provide route options to a destination based on traffic volume, road conditions, and maximum speed. It can then prescribe the best route based on user-defined objectives such as shortest distance or quickest time.

## Diagnostic Analytics
Diagnostic analytics enhances the descriptive analytics process by digging in deeper and attempting to discover the cause(s).

The diagnostic analytics process is as follows:

-Identify anomalies (inconsistencies) in data sets  <br>
-Collect data related to the anomalies  <br>
-Use statistical techniques to uncover relationships and trends that could explain the anomalies  <br>
-Present possible causes  <br>

An example of diagnostic analytics is using subscription cancellations, correlated with customer comments and ratings, to determine the most common reasons why users cancel subscriptions. Another example would be determining whether there is a correlation between the demographics of consumers and their purchasing patterns at specific times of year.

# The Data Analysis Process
There are many different models of data analytics, and in this course, we will use the six-step Data Analysis Lifecycle shown in the figure below. Think of this model as iterative, meaning that some steps could be repeated multiple times before decision makers are confident enough to move forward to the next step.

![Screenshot 2023-07-25 112526](https://github.com/kirannavale/Portfolio-Projects/assets/34519689/e377ccfc-25bb-4833-89d0-483610effb61)

/Asking the Question - The analytics process always starts with a question to be answered. Some questions are simple, such as “which bicycle color is most popular with our younger buyers?” Others are very complex, such as “why are certain types of cancer cells exhibiting resistance to radiation treatments?”<br>
/Getting the data - This step involves the process of locating and obtaining data that is relevant to the question, and then determining if there is enough data to complete the analysis.<br>
/Investigating the data - Data comes in many forms and from many different sources. This step involves determining if the data is complete and contains the relevant information for the analysis.<br>
/Preparing the data - This step can involve many tasks to transform the data into a format appropriate for the tools that will be used to analyze and present the data. This process is sometimes referred to as “cleaning” the data, because there may be blank records or obvious errors in the data set.<br>
/Analyzing the data - Analysis is the process of identifying patterns, correlations, and relationships contained within a data set or sets to draw inferences and conclusions. Often, analysis relies on statistical techniques and software tools such as spreadsheets and visualization applications.<br>
/Presenting the results - This is usually the last step for data analysts. It is the process of communicating the results to decision-makers. This can be done in the form of a report, graphical representations, or a combination of both. Sometimes the data analyst is also asked to recommend actions based on results.

## Business Understanding
Analysts generally work on projects that closely follow some version of the Data Analysis Lifecycle described above. In the first step of the process, Asking the Question, the goal of each project is defined. Goals for projects are based on external (client) or internal (stakeholder) business requirements—this is why business understanding is key to successful data analysis. Businesses often have very different goals, but every type of business benefits from understanding their data to gain insights into their processes, procedures and customer behaviors. Let’s examine a couple of example projects and the questions that might be answered by an analysis.

Where should the marketing budget be concentrated to increase new business? A bicycle manufacturer wants to identify areas where sales could be improved by targeted marketing efforts. Using sales records, customer demographic information and products, they can decide where advertising is most likely to increase new business.

How can a company make sure they are stocking the right inventory? A medical supply company for hospitals knows that certain common conditions require high volumes of certain supplies, and that patient demographics are associated with certain diagnoses of these conditions. They want to use hospital data to gain insights into patient demographics and common diagnoses to identify patterns. Analysts can help the company find these patterns and ensure that they have the right supplies on hand at the right times to meet the needs of their customers.

What products or services should be recommended to a customer? Recommendation systems are a popular way to introduce current consumers to new products and services. Think of the many recommendation systems that you encounter during your online experiences. A very common example of this is video subscription services, which often analyze customer purchasing habits, ratings and reviews to help determine which products and services to recommend to those customers.

But data analysis is not limited to just business problems. Think about your personal interests and questions that you might want to answer in order to gain a better understanding of the field. As you work through the labs and activities in the course, you will be building valuable skills for each step of the Data Analysis Lifecycle. Potential employers expect to see evidence that demonstrates the ability to complete a project from start to finish. For data analyst positions, this is usually done through a project portfolio. Starting now and continuing through this course, you can be planning to create your own personal project portfolio to share with prospective employers.

## Asking the Right Questions

/Objectives <br>
This provides opportunities for learners to begin a personal analytic project. <br>

Choose a topic to investigate. <br>

Formulate a question to answer with the analysis. <br>

Determine the data elements that are needed to find the answers. <br>

/Background / Scenario
In this lab, you will begin your first analytic project, starting with the “Ask the Question” step of the process. Choose a topic that you are interested in and that you want to see through to the end. In most data analysis projects, there is an identified need or benefit that informs the question that starts the process. The question determines what type of analysis and what data elements are necessary to produce the desired outcomes.

Once you have formulated a question, you can make hypothesis as to the outcome of the analysis. After completing your analysis, later in the course, you can compare your initial hypothesis with the actual outcome.

/Required Resources
A device with an internet browser and an internet connection. 
/Instructions
Part 1: Determine a Topic
Did you ever wonder about something that you were unable to find an answer for, or that you were skeptical of the answers that you did find? Topics that you want to know more about are excellent choices for your first analytic project.

/Step 1: Ask a question

It could be something as simple as “does having Batman appear in your movie make it more successful at the box office?” or “which flavors of ice cream are most popular with different age groups?”. Or it could be something more complex, like “what cryptocurrency is the best investment based on past year performance?”.

/Write down your question. What is the benefit of determining the answer to this question? In most data analytic projects, the potential benefit is the reason for the project. For example, a marketing executive would benefit from knowing which age groups prefer certain flavors of ice cream, because it could help determine where to place advertising, or which flavors to stock in towns with colleges or universities.<br>
Review the four different types of data analysis described in the module. What type of analysis do you think fits best to uncover the answer to your question? In most cases, descriptive analysis is a good choice if the answer will be determined by analyzing historical data. <br>

Step 2: Determine the Data Needed

Now that you have a question in mind, think about the data elements that you might need to analyze in order to come up with an answer to the question.

Make a list of the data elements that you identify. An example: If the question is “does having Batman appear in your movie make it more successful at the box office?”, some of the needed data elements would be:
-Movies with Batman as a character <br> 
-Successful movies made in the same timeframe <br>
-Box office sales and revenue of movies in the same timeframe <br>
-Open a web browser and use any search engine to search for the data elements that you have identified. <br>
-List sources that you found that may have data relating to the elements you identified. <br>
-You may also want to investigate sources, such as Kaggle, that provide sample data for analysis. <br>

Reflection Questions
-Why is it important to identify the question that needs to be answered by the analysis before beginning the project? <br>
-Name some sources of open data for analysis that you found while searching for your data elements. <br>


## Tools Used For Data Analysis -

 /Excel -Excel is powerful and very popular for performing small-scale data analysis, calculations, data summaries, and data visualizations.

Excel skills you need :

-Perform data cleaning by removing blank spaces as well as incorrect and outdated information <br>
-Format and adjust data using conditional formatting <br>
-Perform data calculations using formulas <br>
-Organize data using sorting and filtering <br>
-Create visualizations using graphing and charting <br>
-Calculate, summarize, and analyze data using pivot tables <br>
-Aggregate data for analysis <br>

/SQL- SQL, which stands for Structured Query Language, is a powerful database management tool that allows data analysts to retrieve and interact with selections of data that are stored in relational databases.
Relational databases can solve some of the issues that occur with flat file databases, such as duplicate or inconsistent data. Relational databases store information in tables; the definitions of the tables, relationships between tables and other characteristics of the database are stored in a schema.

SQL skills you need :

-Create tables <br>
-Retrieve data using SQL index<br>
-Retrieve data using SQL queries<br>
-Aggregate data with SQL joins<br>

/Power Bi/Tableau- used to visualise data.


 ## Observations, Variables, and Values

A variable in this context is anything that varies from one instance to another, that can be measured, and whose value can be manipulated or controlled in theoretical scenarios.


![Screenshot 2023-07-25 114726](https://github.com/kirannavale/Portfolio-Projects/assets/34519689/6dccd011-10c9-4335-8483-be052d19b677)

Categorical variables indicate membership in a particular group and have a discrete or specific qualitative value. They are further classified into two types:

/Nominal - These are variables that consist of two or more discrete categories whose value is assigned based on the identity of the object. Examples are gender, eye color or type of animal.

/Ordinal - These are variables that consist of two or more categories in which order matters in the value. Examples are student class rank (1st, 2nd, 3rd) or satisfaction survey scales (dissatisfied, neutral, satisfied).

Numerical variables are quantitative values:

/Continuous - These are variables that are quantitative and can be measured along a continuum or range of values. There are two types of continuous variables: Interval variables can have any value within the range of values, and examples are temperature or time; Ratio variables are special interval variables where a value of zero (0) can mean that there is none of that variable and examples are income or sales volume.

/Discrete - These types of continuous variables are quantitative but have a specific value from a finite set of values. Examples include the number of sensors activated in a network, or the number of cars in a lot.

Why is it important to know what types of variables are in your data set? Some types of analysis and data visualizations are designed to work with certain types of data. How you might choose to present the results of the analysis will depend on the type of variables used in the data. Some types of variables lend themselves better to bar graphs, while others may allow for more examination and discovery using a scatter plot. Examples of some of the suggested types of graphs that represent the different types of variables can be seen in the figure above.


## Preparing and cleaning data for Analysis

![Screenshot 2023-07-25 115246](https://github.com/kirannavale/Portfolio-Projects/assets/34519689/f5261147-d725-40d9-9ad2-b8fe5eeaf001)


/Selecting Relevant Data-
Selecting relevant data for your analysis includes determining the type(s) of data that you need and finding a source for the data. When selecting data for a project, it is important to focus on finding data that may provide insights into your original business question. For example, if you are seeking to understand demographic characteristics of people who bought Product X in the past year, you should only be using data that is directly related to Product X. This process is crucial to ensuring the validity and reliability of your analysis. Sometimes the data you need to answer your questions isn’t readily available. It may be necessary to establish new procedures to collect the data required for your analysis. Other times, it may involve combining data from multiple sources into a format that can be analyzed.


Some questions that you should ask yourself when selecting a data source:

-What data points are necessary to inform your analysis?

-Do I already have access to this data, or must I find a dataset from another source?

-Where are reliable and verifiable sources of this data?

-How often is the relevant data collected and updated?

-How is the data licensed for use, and is there a cost?

-Is the data in a format that I can use, or convert to use, with my tools?

## Static and Streaming Data
There are two types of data that analysts work with: static data and streaming data. Data that is received and stored prior to performing analysis on the data is considered static data. When each event is processed and analyzed as it is received and subsequent results are used or stored, the data is referred to as streaming data.

## Data Types and Formats

![Screenshot 2023-07-25 115937](https://github.com/kirannavale/Portfolio-Projects/assets/34519689/b0afd913-bd89-4ff0-b361-453cdb94bc22)

## Data Preparation-

##  ETL and ELT Processes-
ETL and ELT are two versions of the same process for moving data through a pipeline. They contain the same steps but in different orders for different use cases.

Extract, Transform and Load (ETL) is a process for collecting data from this variety of sources, transforming the data, and then loading the data into a database. One company’s data might be found in Word documents, spreadsheets, plain text, PowerPoints, emails and PDF files. Another company’s data may be housed in relational databases. This data can be stored in a variety of different formats, making it difficult to combine and analyze, so the transformation happens before loading.

In an Extract, Load, Transform (ELT) process, the load and transform steps are reversed. ELT enables raw data to skip the transformation step and go straight to storage in an unstructured form. Transformation then occurs on the stored data as it is used. The ELT process is used primarily for large amounts of unstructured data.

/Step 1. Extract
In this step, data is located and gathered from various sources in order to be converted into a single format for analysis. The data may be extracted from a relational database, NoSQL, flat files, XML files, or other formats.

/Step 2. Transform
Data usually must be transformed before it can be loaded into a data warehouse for analysis. The transform step uses rules to transform the source data to the type of data needed for the target database. This includes converting any measured data to the same dimension (e.g., Imperial to Metric). The transformation step also requires several additional tasks. Some of these tasks are joining data from several sources, aggregating, sorting, determining new values that are calculated from aggregated data, and then applying validation rules.

Data (possibly including some empty or error data) may go through another part of the transform step known as ‘cleaning’ or ‘scrubbing’ data, and validation lets you know whether the data needs cleaning. Some examples of data cleaning are removing blank records and standardizing formats such as date, time, and location. The cleaning part of the transform step further ensures the consistency of the source data.

/Step 3. Load
The transformed data is then loaded into the database for querying. The actual load process varies widely, depending on the types of source data, the type of target database, and the type of querying that is to be done. Some organizations may also overwrite existing data with newer cumulative data. During the load step, rules that have been defined in the database schema are applied. These rules check for necessary characteristics like uniqueness and consistency of data or that mandatory fields aren’t empty. These rules help to ensure that the loading and any subsequent querying of the data is successful.

## Preparing and Cleaning Data for Analysis Summary

Data needs to be cleaned before it can be analyzed. Cleaning the data makes it easier to read and interpret, ensures consistency and accurate results, and enables a better decision-making process.


## Analysing data using statistics
To do their jobs efficiently and effectively, data analysts must have a basic understanding of statistics. This is because data analytics relies heavily on statistics in the process of analyzing and interpreting data.

# Descriptive Statistics
After the problem statement (also known as the question to be asked) and population is determined, some form of statistical analysis is needed. There are two key branches of statistics that we will discuss in this course:

-Descriptive Statistics <br>
-Inferential Statistics

Descriptive statistics are used to describe or summarize the values and observations of a data set. For example, a fitness tracker logged a person’s daily steps and heart rate for a 10-day period. If the person met their fitness goals in 6 out of the 10 days, then they were successful 60% of the time. Over that 10-day period, you could observe that the person’s heart rate was a maximum of 140 beats per minute (bpm), but an average of 72 bpm. These observations would be descriptive statistics that could be used to describe and simplify the data set.

Basic descriptive statistics might include the total number of data points in a data set, the range of values that exist for those numeric data points, or the number of times a given value appears in a data set. Descriptive statistics may also answer questions about the occurrence of trends.
The answers to these questions can be provided in numerical or graphical formats. Results of descriptive statistics are often represented in pie charts, bar charts or histograms. One important point to note is that while descriptive statistics describe the current or historical state of the observed population, it does not allow for:
-comparison of groups <br>
-conclusions to be drawn <br>

predictions to be made about data sets that are not in the population <br>
In the fitness tracker example, we cannot infer that the person has poor health because they were only successful in meeting their goal 60% of the time. We also cannot use the data set for this one person to predict the fitness performance for others with similar characteristics. This is where inferential statistics becomes important.

## Inferential Statistics
Descriptive statistics allows you to summarize findings based on data that you already have recorded or observed about a population. However, there are situations in which gathering data for a very large population may not always be practical or even possible. It is possible, however, to study a smaller representative sample of a population and use inferential statistics to test hypotheses and draw conclusions about the larger population.

Inferential statistics is the process of collecting, analyzing and interpreting the data gathered from a sample to generalize or predict something about a population. When a representative sample is used, methodological concerns may arise and must be addressed, such as whether the groups chosen for the study or the environment in which a study is carried out accurately reflects characteristics of the larger group. Typically, these types of analyses will include different sampling techniques to reduce error and increase confidence in the generalized findings. The type of sampling technique used will depend on the type of data.


## Statistics and Big Data

Different statistical approaches are used in big data analytics. As we know, descriptive statistics describe a sample. This is useful for understanding the sample data and for determining the quality of the data. Problems can occur when dealing with large amounts of data that come from multiple sources. Data points can be corrupted, incomplete, or missing entirely. Descriptive statistics can help determine how much of the data in the sample is good for the analysis and identify criteria for removing data that is inappropriate or problematic. Graphs of descriptive statistics are a helpful way to make quick judgements about the quality of a sample.

For example, in a sample of tweets selected for analysis, some contain only text characters, while others contain both characters and images. The type of analysis or question to be answered with analysis will determine whether tweets that contain images or tweets with no images should be analyzed. This will identify tweets that are invalid based on a very simple criterion, because images contain information that must be considered in the analysis if the tweets using images are included in the sample.

A number of inferential analyses are very commonly used in big data analytics:

-Cluster analysis - Used to find groups of observations that are similar to each other<br>
-Association analysis - Used to find co-occurrences of values for different variables<br>
-Regression analysis - Used to quantify the relationship, if any, between the variations of one or more variables


## Choosing the Right Visualization for the Job

Common Types of Data Visualizations

Selectable image component. Select each item to show more information.<br>
There are many types of data visualizations. Determining the best option usually depends on the answers to the following questions, among others:

-How many variables are you going to show?<br>
-How many data points are in each variable?<br>
-Is your data over time or are you comparing data points at a single point in time?

/Line Chart
Line charts are one of the most commonly used types of comparison charts. Use line charts when you have a continuous set of data, the number of data points is high, and/or you would like to show a trend in the data over time. Some examples include:
-Quarterly sales for the past five years<br>
-Number of customers per week in the first year of a new retail shop<br>
-Change in a stock’s price on one day, from opening to closing bell<br>


/Column Chart
Column charts are positioned vertically. They are probably the most common chart type used to display the values of a specific variable across similar categories. Some examples include:

Populations of the BRICS nations (Brazil, Russia, India, China, and South Africa)<br>
Last year’s sales for the top four car companies<br>
Average student test scores for six math classes<br>

/Bar Chart
Bar charts are similar to column charts except they are positioned horizontally and hence used slightly differently (for example, they do not usually show changes over time). Longer bars indicate larger values. They are best used when the names for each data point is long, because there is space to write the information. Some examples include:

-Gross domestic product (GDP) of the 25 highest-producing nations in a given year<br>
-Number of cars sold by each sales representative in a group<br>
-Exam scores for each student in a math class<br>

/Pie Chart
Pie charts are used to show the composition of a total. Segments of different sizes visually represent percentages of that total. The sum of the segments must equal 100%.

Some examples include:
Annual expenses for a corporation (e.g., rent, administrative, utilities, production)<br>
A country’s energy sources (e.g., oil, coal, gas, solar, wind)<br>
Survey results for a group’s favorite type of movie (e.g., action, romance, comedy, drama, science fiction)<br>

/Scatter Plot
Scatter plots are very popular for visualizing correlations, or to show the distribution of many data points. Scatter plots are also useful for demonstrating clustering or identifying outliers in the data.

Some examples include:
Comparing life expectancy to GDP for each country in a group<br>
Comparing the daily sales of ice cream at a given location to the average outside temperature<br>
Comparing the weight to the height of each person in a group<br>


## Addressing Anomalies in Data
/Outliers and Anomalies-
Before data analysis can begin, considerable time must be spent cleaning the data. During the data cleaning phase, you may find outliers, or anomalies, in the data. If so, they need to be investigated so that the data can be corrected or the meaning of the outlying data point can be understood.

An outlier is defined as a value or data point that varies significantly from others, either much smaller or much greater. Sometimes outliers are mistakes and sometimes they represent an important piece of information. In the figure, the data point at the extreme bottom right is an outlier. All the other data points cluster along the trend line.

![Screenshot 2023-07-25 123054](https://github.com/kirannavale/Portfolio-Projects/assets/34519689/12e0cde1-34c8-4ddd-81e5-f61791d45a9a)

In the data analysis process, outliers that are the result of mistakes can lead to anomalies in the results obtained, while outliers that are not errors can be very important to an analysis. This is why investigating anomalies is a very important part of the data cleaning process—it ensures that data can be analyzed effectively and generate accurate and valid results.

With small data sets it may be relatively easy to spot outliers by sorting or filtering the data. But when it comes to large datasets and big data, other tools are required. Two common types of data visualization used to find outliers are scatter plots and box plots.



## types of bias that can impact data analysis results

Bias in the selection and interpretation of data can create results that may not reflect the true situation. Bias must be recognized and mitigated for the results to be valid. Five types of bias that can influence the results of analysis are confirmation bias, interpretation bias, selection bias, information bias and predictive bias.

ethical issues presented by the use of data.

Privacy and security of data are two concerns that are being addressed by laws and regulations. Some of the most restrictive regulations are found in the General Data Protection Regulation (GDPR), which was adopted by the European Union, which governs how personal data of individuals in the EU may be processed and transferred. The components of the CIA triad (confidentiality, integrity, and availability) are a guideline for data security for an organization.















